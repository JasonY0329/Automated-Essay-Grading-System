{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfB0qwV52nM7",
        "outputId": "e9f2ca49-ec38-41a0-acce-fad4b07808ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn import linear_model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import scipy\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "LDw8NgEy2sWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "728df495-8568-402f-8da8-b2a490607915"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/346 project/training_set_rel3.tsv', sep='\\t', encoding='ISO-8859-1')\n",
        "columns = ['essay_id', 'essay_set', 'essay', 'domain1_score']\n",
        "asap = pd.DataFrame(train_data, columns=columns)\n",
        "sets=asap['essay_set'].unique()\n",
        "scores=pd.DataFrame(asap,columns=['essay_set','domain1_score'])\n",
        "scores_grp=scores.groupby(['essay_set'],as_index=False)\n",
        "essay=pd.DataFrame(sets,columns=['sets'])\n",
        "essay['counts']=scores_grp.count()['domain1_score']\n",
        "essay['min']=scores_grp.min()['domain1_score']\n",
        "essay['max']=scores_grp.max()['domain1_score']\n",
        "essay['med']=scores_grp.median()['domain1_score']\n",
        "scores = {}\n",
        "for es in sets:\n",
        "    min_es = asap[asap['essay_set'] == es].domain1_score.min()\n",
        "    max_es =  asap[asap['essay_set'] == es].domain1_score.max()\n",
        "    scores[es] = (min_es, max_es)"
      ],
      "metadata": {
        "id": "1mmQ6Dq43LLZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def minmax_scaler(es, score):\n",
        "    return (score - scores[es][0]) / (scores[es][1] - scores[es][0])\n",
        "\n",
        "def inverse_scaler(es, score):\n",
        "    return round(score * (scores[es][1] - scores[es][0]) + scores[es][0])\n",
        "def scale_dataset(asap):\n",
        "    for row in range(len(asap)):\n",
        "        asap.loc[row, 'nscore'] = minmax_scaler(asap.loc[row, 'essay_set'], asap.loc[row, 'domain1_score'])\n",
        "    return asap\n",
        "asap = scale_dataset(asap)\n",
        "def vectorizer(X_train, X_val, X_test):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X_train = vectorizer.fit_transform(X_train)\n",
        "    if len(X_val) > 0:\n",
        "        X_val = vectorizer.transform(X_val)\n",
        "    X_test = vectorizer.transform(X_test)\n",
        "    return X_train, X_val, X_test"
      ],
      "metadata": {
        "id": "14iY75mA5EZ_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_qwk = 0.0\n",
        "for score in scores:\n",
        "    data  = asap[asap['essay_set'] == score]\n",
        "    X_train, X_test, y_train_scaled, y_test_scaled, y_train, y_test = train_test_split(data['essay'], data['nscore'], data['domain1_score'], test_size=0.25, random_state=92)\n",
        "\n",
        "    X_val=pd.DataFrame()\n",
        "    X_train_vec, X_val, X_test_vec = vectorizer(X_train, X_val, X_test)\n",
        "\n",
        "    #svr\n",
        "    svr = SVR(kernel='linear')\n",
        "    svr.fit(X_train_vec, y_train_scaled)\n",
        "    y_pred = svr.predict(X_test_vec)\n",
        "\n",
        "    y_pred = [inverse_scaler(score, pred) for pred in y_pred]\n",
        "\n",
        "    qwk = cohen_kappa_score(y_test, y_pred, weights='quadratic')\n",
        "    total_qwk += qwk\n",
        "\n",
        "    print('QWK for prompt {} is {:.3f}'.format(score, qwk))\n",
        "\n",
        "qwk_results = total_qwk / 8\n",
        "print(\"SVR: The average QWK {:.3f}\".format(qwk_results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJBFvC4U5OwM",
        "outputId": "d353422d-5353-453b-af2b-1e4d20e52d1d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QWK for prompt 1 is 0.706\n",
            "QWK for prompt 2 is 0.494\n",
            "QWK for prompt 3 is 0.501\n",
            "QWK for prompt 4 is 0.731\n",
            "QWK for prompt 5 is 0.692\n",
            "QWK for prompt 6 is 0.744\n",
            "QWK for prompt 7 is 0.682\n",
            "QWK for prompt 8 is 0.477\n",
            "SVR: The average QWK 0.628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_qwk = 0.0\n",
        "for score in scores:\n",
        "    data  = asap[asap['essay_set'] == score]\n",
        "    X_train, X_test, y_train_scaled, y_test_scaled, y_train, y_test = train_test_split(data['essay'], data['nscore'], data['domain1_score'], test_size=0.2, random_state=42)\n",
        "\n",
        "    X_val=pd.DataFrame()\n",
        "    X_train_vec, X_val, X_test_vec = vectorizer(X_train, X_val, X_test)\n",
        "\n",
        "    #brr\n",
        "    brr = linear_model.BayesianRidge()\n",
        "    brr.fit(X_train_vec.toarray(), y_train_scaled)\n",
        "    y_pred = brr.predict(X_test_vec)\n",
        "\n",
        "    y_pred = [inverse_scaler(score, pred) for pred in y_pred]\n",
        "\n",
        "    qwk = cohen_kappa_score(y_test, y_pred, weights='quadratic')\n",
        "    total_qwk += qwk\n",
        "\n",
        "    print('QWK for prompt {} is {:.3f}'.format(score, qwk))\n",
        "\n",
        "qwk_results = total_qwk / 8\n",
        "print(\"BRR: The average QWK {:.3f}\".format(qwk_results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9o_Fxc3B52Mz",
        "outputId": "91970646-fc97-43b9-e6cc-0c72d0d174b0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QWK for prompt 1 is 0.699\n",
            "QWK for prompt 2 is 0.556\n",
            "QWK for prompt 3 is 0.526\n",
            "QWK for prompt 4 is 0.672\n",
            "QWK for prompt 5 is 0.700\n",
            "QWK for prompt 6 is 0.751\n",
            "QWK for prompt 7 is 0.720\n",
            "QWK for prompt 8 is 0.564\n",
            "BRR: The average QWK 0.649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_qwk = 0.0\n",
        "for score in scores:\n",
        "    data  = asap[asap['essay_set'] == score]\n",
        "    X_train, X_test, y_train_scaled, y_test_scaled, y_train, y_test = train_test_split(data['essay'], data['nscore'], data['domain1_score'], test_size=0.2, random_state=42)\n",
        "\n",
        "    X_val=pd.DataFrame()\n",
        "    X_train_vec, X_val, X_test_vec = vectorizer(X_train, X_val, X_test)\n",
        "\n",
        "    #xgb\n",
        "    xgb = XGBRegressor(n_estimators=800, seed=42, learning_rate = 0.015, max_depth=5, eval_metric='rmse')\n",
        "    xgb.fit(X_train_vec, y_train_scaled)\n",
        "    y_pred = xgb.predict(X_test_vec)\n",
        "\n",
        "    y_pred = [inverse_scaler(score, pred) for pred in y_pred]\n",
        "\n",
        "    qwk = cohen_kappa_score(y_test, y_pred, weights='quadratic')\n",
        "    total_qwk += qwk\n",
        "\n",
        "    print('QWK for prompt {} is {:.3f}'.format(score, qwk))\n",
        "\n",
        "qwk_results = total_qwk / 8\n",
        "print(\"XGB: The average QWK {:.3f}\".format(qwk_results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gurVSC065MX",
        "outputId": "30096701-b59e-406c-e1b4-a1ed19bc9d6d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QWK for prompt 1 is 0.771\n",
            "QWK for prompt 2 is 0.613\n",
            "QWK for prompt 3 is 0.610\n",
            "QWK for prompt 4 is 0.746\n",
            "QWK for prompt 5 is 0.712\n",
            "QWK for prompt 6 is 0.769\n",
            "QWK for prompt 7 is 0.730\n",
            "QWK for prompt 8 is 0.560\n",
            "XGB: The average QWK 0.689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "import re\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import words\n",
        "\n",
        "def num_chars_essay(text):\n",
        "    return len(list(text))\n",
        "\n",
        "def num_puncts_essay(text):\n",
        "    return len([char for char in list(text) if char in string.punctuation])\n",
        "\n",
        "def num_words_essay(text):\n",
        "    return len(word_tokenize(text))\n",
        "\n",
        "def num_unique_words_essay(text):\n",
        "    return len(set(word_tokenize(text)))\n",
        "\n",
        "def num_sents_essay(text):\n",
        "    return len(sent_tokenize(text))\n",
        "\n",
        "def num_numbers_essay(text):\n",
        "    return len(re.sub(\"[^0-9]\", \"\", text))\n",
        "\n",
        "def num_correct_words(text):\n",
        "    correct_words = words.words()\n",
        "    return len(list(set(correct_words) & set(word_tokenize(text)))) / num_words_essay(text)\n",
        "\n",
        "def lexical_features(data):\n",
        "\n",
        "    asap = pd.DataFrame(data)\n",
        "    asap['num_chars_essay'] = asap['essay'].apply(num_chars_essay)\n",
        "    asap['num_puncts_essay'] = asap['essay'].apply(num_puncts_essay)\n",
        "    asap['num_words_essay'] = asap['essay'].apply(num_words_essay)\n",
        "    asap['num_unique_words_essay'] = asap['essay'].apply(num_unique_words_essay)\n",
        "    asap['num_numbers_essay'] = asap['essay'].apply(num_numbers_essay)\n",
        "    asap['num_sents_essay'] = asap['essay'].apply(num_sents_essay)\n",
        "    return asap\n"
      ],
      "metadata": {
        "id": "xxiRe_ibBBT1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asap = lexical_features(asap)\n",
        "columns = ['num_chars_essay', 'num_puncts_essay', 'num_words_essay', 'num_unique_words_essay', 'num_numbers_essay', 'num_sents_essay']\n",
        "scaler = MinMaxScaler()\n",
        "asap[columns] = scaler.fit_transform(asap[columns])\n"
      ],
      "metadata": {
        "id": "uNFZwZZ6BIfd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def svr_fn(asap_train, asap_val, asap_test):\n",
        "    total_qwk = 0.0\n",
        "    print(' Prompt   Val    Test ')\n",
        "\n",
        "    for prompt in scores:\n",
        "        X_train  = asap_train[asap_train['essay_set'] == prompt]\n",
        "        X_val = asap_val[asap_val['essay_set'] == prompt]\n",
        "        X_test = asap_test[asap_test['essay_set'] == prompt]\n",
        "\n",
        "        # TF-IDF\n",
        "        X_train_vec, X_val_vec, X_test_vec = vectorizer(X_train['essay'], X_val['essay'], X_test['essay'])\n",
        "\n",
        "        # Lexical features\n",
        "        columns = ['num_chars_essay', 'num_puncts_essay', 'num_words_essay', 'num_unique_words_essay', 'num_numbers_essay', 'num_sents_essay']\n",
        "\n",
        "        # Scale\n",
        "        scaler = MinMaxScaler()\n",
        "        X_train_features = pd.DataFrame(lexical_features(X_train), columns=columns)\n",
        "        X_train_features[columns] = scaler.fit_transform(X_train_features[columns])\n",
        "\n",
        "        X_val_features = pd.DataFrame(lexical_features(X_val), columns=columns)\n",
        "        X_val_features[columns] = scaler.fit_transform(X_val_features[columns])\n",
        "\n",
        "        X_test_features = pd.DataFrame(lexical_features(X_test), columns=columns)\n",
        "        X_test_features[columns] = scaler.fit_transform(X_test_features[columns])\n",
        "\n",
        "        # Merge both features (TF-IDF and lexical)\n",
        "        X_train_all = scipy.sparse.hstack([X_train_vec, X_train_features])\n",
        "        X_val_all = scipy.sparse.hstack([X_val_vec, X_val_features])\n",
        "        X_test_all = scipy.sparse.hstack([X_test_vec, X_test_features])\n",
        "\n",
        "        #svr\n",
        "        svr = SVR(kernel='linear')\n",
        "        svr.fit(X_train_all, X_train['nscore'].tolist())\n",
        "        y_pred_val = svr.predict(X_val_all) # Validation\n",
        "        y_pred_test = svr.predict(X_test_all) # Test\n",
        "\n",
        "        # invert y_pred into the essay set scoring range\n",
        "        y_pred_val = [inverse_scaler(prompt, pred) for pred in y_pred_val]\n",
        "        y_pred_test = [inverse_scaler(prompt, pred) for pred in y_pred_test]\n",
        "\n",
        "        val_qwk = cohen_kappa_score(X_val['domain1_score'].tolist(), y_pred_val, weights='quadratic')\n",
        "        qwk = cohen_kappa_score(X_test['domain1_score'].tolist(), y_pred_test, weights='quadratic')\n",
        "        total_qwk += qwk\n",
        "        print('  {}       {:.3f}  {:.3f} '.format(prompt, val_qwk, qwk))\n",
        "    qwk_results = total_qwk / 8\n",
        "    print(\"SVR: The average QWK {:.3f}\".format(qwk_results))\n",
        "train, test = train_test_split(asap,test_size=0.25, random_state=42)\n",
        "svr_fn(train, test, test)"
      ],
      "metadata": {
        "id": "DtaimxhyBhqJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b4cae8-a341-49a2-9a63-a0d63ecb80f6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Prompt   Val    Test \n",
            "  1       0.812  0.812 \n",
            "  2       0.672  0.672 \n",
            "  3       0.533  0.533 \n",
            "  4       0.755  0.755 \n",
            "  5       0.742  0.742 \n",
            "  6       0.778  0.778 \n",
            "  7       0.731  0.731 \n",
            "  8       0.704  0.704 \n",
            "SVR: The average QWK 0.716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def brr_fn(asap_train, asap_val, asap_test):\n",
        "    total_qwk = 0.0\n",
        "    print(' Prompt   Val    Test ')\n",
        "\n",
        "    for prompt in scores:\n",
        "        X_train  = asap_train[asap_train['essay_set'] == prompt]\n",
        "        X_val = asap_val[asap_val['essay_set'] == prompt]\n",
        "        X_test = asap_test[asap_test['essay_set'] == prompt]\n",
        "\n",
        "        X_train_vec, X_val_vec, X_test_vec = vectorizer(X_train['essay'], X_val['essay'], X_test['essay'])\n",
        "\n",
        "        columns = ['num_chars_essay', 'num_puncts_essay', 'num_words_essay', 'num_unique_words_essay', 'num_numbers_essay', 'num_sents_essay']\n",
        "\n",
        "\n",
        "        X_train_features = pd.DataFrame(lexical_features(X_train), columns=columns)\n",
        "        X_val_features = pd.DataFrame(lexical_features(X_val), columns=columns)\n",
        "        X_test_features = pd.DataFrame(lexical_features(X_test), columns=columns)\n",
        "\n",
        "        X_train_all = scipy.sparse.hstack([X_train_vec, X_train_features])\n",
        "        X_val_all = scipy.sparse.hstack([X_val_vec, X_val_features])\n",
        "        X_test_all = scipy.sparse.hstack([X_test_vec, X_test_features])\n",
        "\n",
        "        #brr\n",
        "        brr = linear_model.BayesianRidge()\n",
        "        brr.fit(X_train_all.toarray(), X_train['nscore'].tolist())\n",
        "        y_pred_val = brr.predict(X_val_all) # Validation\n",
        "        y_pred_test = brr.predict(X_test_all) # Test\n",
        "\n",
        "        y_pred_val = [inverse_scaler(prompt, pred) for pred in y_pred_val]\n",
        "        y_pred_test = [inverse_scaler(prompt, pred) for pred in y_pred_test]\n",
        "\n",
        "        val_qwk = cohen_kappa_score(X_val['domain1_score'].tolist(), y_pred_val, weights='quadratic')\n",
        "        qwk = cohen_kappa_score(X_test['domain1_score'].tolist(), y_pred_test, weights='quadratic')\n",
        "        total_qwk += qwk\n",
        "        print('  {}       {:.3f}  {:.3f} '.format(prompt, val_qwk, qwk))\n",
        "    qwk_results = total_qwk / 8\n",
        "    print(\"BRR: The average QWK {:.3f}\".format(qwk_results))\n",
        "train, test = train_test_split(asap,test_size=0.25, random_state=42)\n",
        "brr_fn(train, test, test)"
      ],
      "metadata": {
        "id": "RpmCnN5ZMSXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9892d95e-5859-4984-d48d-f72eea3b2071"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Prompt   Val    Test \n",
            "  1       0.817  0.817 \n",
            "  2       0.686  0.686 \n",
            "  3       0.645  0.645 \n",
            "  4       0.770  0.770 \n",
            "  5       0.784  0.784 \n",
            "  6       0.814  0.814 \n",
            "  7       0.777  0.777 \n",
            "  8       0.741  0.741 \n",
            "BRR: The average QWK 0.754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def xgboost_fn(asap_train, asap_val, asap_test):\n",
        "\n",
        "    total_qwk = 0.0\n",
        "    print(' Prompt   Val    Test ')\n",
        "\n",
        "\n",
        "    for prompt in scores:\n",
        "        X_train  = asap_train[asap_train['essay_set'] == prompt]\n",
        "        X_val = asap_val[asap_val['essay_set'] == prompt]\n",
        "        X_test = asap_test[asap_test['essay_set'] == prompt]\n",
        "\n",
        "        X_train_vec, X_val_vec, X_test_vec = vectorizer(X_train['essay'], X_val['essay'], X_test['essay'])\n",
        "\n",
        "        columns = ['num_chars_essay', 'num_puncts_essay', 'num_words_essay', 'num_unique_words_essay', 'num_numbers_essay', 'num_sents_essay']\n",
        "\n",
        "        X_train_features = pd.DataFrame(lexical_features(X_train), columns=columns)\n",
        "        X_val_features = pd.DataFrame(lexical_features(X_val), columns=columns)\n",
        "        X_test_features = pd.DataFrame(lexical_features(X_test), columns=columns)\n",
        "\n",
        "        X_train_all = scipy.sparse.hstack([X_train_vec, X_train_features])\n",
        "        X_val_all = scipy.sparse.hstack([X_val_vec, X_val_features])\n",
        "        X_test_all = scipy.sparse.hstack([X_test_vec, X_test_features])\n",
        "\n",
        "        #xgb\n",
        "        xgb = XGBRegressor(n_estimators=800, seed=42, learning_rate = 0.015, max_depth=5, eval_metric='rmse')\n",
        "        xgb.fit(X_train_all, X_train['nscore'].tolist()) # Training\n",
        "        y_pred_val = xgb.predict(X_val_all) # Validation\n",
        "        y_pred_test = xgb.predict(X_test_all) # Test\n",
        "\n",
        "        y_pred_val = [inverse_scaler(prompt, pred) for pred in y_pred_val]\n",
        "        y_pred_test = [inverse_scaler(prompt, pred) for pred in y_pred_test]\n",
        "\n",
        "        val_qwk = cohen_kappa_score(X_val['domain1_score'].tolist(), y_pred_val, weights='quadratic')\n",
        "        qwk = cohen_kappa_score(X_test['domain1_score'].tolist(), y_pred_test, weights='quadratic')\n",
        "        total_qwk += qwk\n",
        "\n",
        "        print('  {}       {:.3f}  {:.3f} '.format(prompt, val_qwk, qwk))\n",
        "    qwk_results = total_qwk / 8\n",
        "    print(\"XGB: The average QWK {:.3f}\".format(qwk_results))\n",
        "train, test = train_test_split(asap,test_size=0.25, random_state=42)\n",
        "xgboost_fn(train, test, test)"
      ],
      "metadata": {
        "id": "sYgtflbEOHD2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e918558e-84a3-449c-cd31-e66791cd31ab"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Prompt   Val    Test \n",
            "  1       0.815  0.815 \n",
            "  2       0.687  0.687 \n",
            "  3       0.673  0.673 \n",
            "  4       0.748  0.748 \n",
            "  5       0.802  0.802 \n",
            "  6       0.808  0.808 \n",
            "  7       0.772  0.772 \n",
            "  8       0.700  0.700 \n",
            "XGB: The average QWK 0.751\n"
          ]
        }
      ]
    }
  ]
}